{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs Available:  []\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os \n",
    "import ast\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers, optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Flatten, Dropout, LSTM, Softmax, Bidirectional, LayerNormalization, BatchNormalization, Input\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import tqdm\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "print(\"GPUs Available: \", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/train_word2.csv\"\n",
    "valid_path = \"data/valid_word2.csv\"\n",
    "test_path = \"data/test_word2.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "valid_df = pd.read_csv(valid_path)\n",
    "# test_df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/word_embed/train\"\n",
    "valid_path = \"data/word_embed/valid\"\n",
    "test_path = \"data/word_embed/test\"\n",
    "\n",
    "train_df = pd.DataFrame()\n",
    "valid_df = pd.DataFrame()\n",
    "test_df = pd.DataFrame()\n",
    "\n",
    "# load train data\n",
    "print(\"loading train data...\")\n",
    "for file in os.listdir(train_path):\n",
    "    df = pd.read_pickle(os.path.join(train_path, file))\n",
    "    train_df = train_df.append(df, ignore_index=True)\n",
    "    \n",
    "# load valid data\n",
    "print(\"loading valid data...\")\n",
    "for file in os.listdir(valid_path):\n",
    "    df = pd.read_pickle(os.path.join(valid_path, file))\n",
    "    valid_df = valid_df.append(df, ignore_index=True)\n",
    "\n",
    "# load test data\n",
    "print(\"loading test data...\")\n",
    "for file in os.listdir(test_path):\n",
    "    df = pd.read_pickle(os.path.join(test_path, file))\n",
    "    test_df = test_df.append(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "train_X = np.array(train_df['word_embed'])\n",
    "train_y = np.array(train_df['stars'])\n",
    "train_y = tf.keras.utils.to_categorical(train_y-1, num_classes=5)\n",
    "\n",
    "valid_X = np.array(valid_df['word_embed'])\n",
    "valid_y = np.array(valid_df['stars'])\n",
    "valid_y = tf.keras.utils.to_categorical(valid_y-1, num_classes=5)\n",
    "\n",
    "# test_X = np.array(test_df['word_embed'].tolist())\n",
    "\n",
    "train_X = np.array([ast.literal_eval(row) for row in tdqm.tqdm(train_X)])\n",
    "valid_X = np.array([ast.literal_eval(row) for row in tdqm.tqdm(valid_X)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape=(18000,)\n",
      "train_y.shape=(18000, 5)\n",
      "valid_X.shape=(2000,)\n",
      "valid_y.shape=(2000, 5)\n",
      "<class 'numpy.ndarray'>\n",
      "(128, 96)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{train_X.shape=}\")\n",
    "print(f\"{train_y.shape=}\")\n",
    "print(f\"{valid_X.shape=}\")\n",
    "print(f\"{valid_y.shape=}\")\n",
    "# print(f\"{test_X.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.argmax(train_y, axis=1), bins=5, color='blue', alpha=0.75, label='train')\n",
    "plt.hist(np.argmax(valid_y, axis=1), bins=5, color='red', alpha=0.75, label='valid')\n",
    "plt.title('Distribution of Stars')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_regularizer = regularizers.L1L2(l1=1e-5, l2=1e-4)\n",
    "bias_regularizer = regularizers.L2(1e-4)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(train_X.shape[1:])))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(learning_rate=0.0005),\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCURACY_THRESHOLD = 0.99\n",
    "class accuryThreasholdCallback(tf.keras.callbacks.Callback): \n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        if(logs.get('accuracy') > ACCURACY_THRESHOLD and logs.get('val_accuracy') > ACCURACY_THRESHOLD):   \n",
    "            print(\"\\nReached %2.2f%% accuracy, so stopping training!!\" %(ACCURACY_THRESHOLD*100))   \n",
    "            self.model.stop_training = True\n",
    "\n",
    "accuracy_threashold_monitor = accuryThreasholdCallback()\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=32, validation_data=(valid_X, valid_y), callbacks=[accuracy_threashold_monitor, early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax[0].plot(history.history['accuracy'])\n",
    "ax[0].plot(history.history['val_accuracy'])\n",
    "ax[0].set_ylabel('accuracy')\n",
    "ax[0].set_xlabel('epoch')\n",
    "ax[0].legend(['train', 'val'], loc='upper right')\n",
    "\n",
    "ax[1].plot(history.history['loss'])\n",
    "ax[1].plot(history.history['val_loss'])\n",
    "ax[1].set_ylabel('loss')\n",
    "ax[1].set_xlabel('epoch')\n",
    "ax[1].legend(['train', 'val'], loc='upper right')\n",
    "fig.suptitle('Model training history')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pred_y = model.predict(valid_X)\n",
    "\n",
    "y_test_not_onehot = np.argmax(valid_y, axis=1)\n",
    "y_pred_not_onehot = np.argmax(valid_pred_y, axis=1)\n",
    "plt.figure(figsize=(5, 5))\n",
    "matrix_confusion = confusion_matrix(y_pred_not_onehot, y_test_not_onehot)\n",
    "sns.heatmap(matrix_confusion, square=True, annot=False, cmap='Blues', fmt='d')\n",
    "\n",
    "for i in range(matrix_confusion.shape[0]):\n",
    "    for j in range(matrix_confusion.shape[1]):\n",
    "        plt.text(j+0.5, i+0.5, f'{matrix_confusion[i, j]}/{np.sum(matrix_confusion[i, :])}', \n",
    "                 horizontalalignment='center', verticalalignment='center', fontsize=7)\n",
    "\n",
    "plt.xlabel('predictions')\n",
    "plt.ylabel('ground truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_y_numerical = np.argmax(valid_y, axis=1)\n",
    "valid_pred_y_numerical = np.argmax(valid_pred_y, axis=1)\n",
    "\n",
    "print(classification_report(valid_y_numerical, valid_pred_y_numerical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # validation\n",
    "print(\"@@@@@@ model prediction on validation set @@@@@@\")\n",
    "index  = np.random.choice(len(valid_df))\n",
    "\n",
    "print(f\"text: {valid_df.loc[index, 'text']}\")\n",
    "\n",
    "valid_stars = valid_df.loc[index, 'stars']\n",
    "print(f\"ground truth: {valid_stars}\")\n",
    "\n",
    "x = valid_df.loc[index, 'word_embed']\n",
    "x = np.array(x)\n",
    "x = x.reshape(1, x.shape[0], x.shape[1])\n",
    "valid_stars_pred = model.predict(x, verbose=0)\n",
    "valid_stars_pred = np.argmax(valid_stars_pred) + 1\n",
    "print(f\"model pred: {valid_stars_pred}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# # testing\n",
    "index = np.random.choice(len(test_df))\n",
    "\n",
    "print(f\"text: {test_df.loc[index, 'text']}\")\n",
    "\n",
    "x = test_df.loc[index, 'word_embed']\n",
    "x = np.array(x)\n",
    "x = x.reshape(1, x.shape[0], x.shape[1])\n",
    "test_stars_pred = model.predict(x, verbose=0)\n",
    "test_stars_pred = np.argmax(test_stars_pred) + 1\n",
    "print(f\"model pred: {test_stars_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(f\"weights/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pred = model.predict(valid_X, verbose=1)\n",
    "test_pred = model.predict(test_X, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pred_df = pd.DataFrame(valid_df)\n",
    "valid_pred_df['stars'] = np.argmax(valid_pred, axis=1) + 1\n",
    "print(valid_pred_df[[\"text\", \"stars\"]].head())\n",
    "\n",
    "test_pred_df = pd.DataFrame(test_df)\n",
    "test_pred_df['stars'] = np.argmax(test_pred, axis=1) + 1\n",
    "print(test_pred_df[[\"review_id\", \"text\", \"stars\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pred_df[[\"text\", \"stars\"]].to_csv(\"data/valid_pred.csv\", index=False)\n",
    "test_df[[\"review_id\", \"text\", \"stars\"]].to_csv(\"data/pred.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('fyp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5688be1e860b42f6f5c12c91b9e760acd4617dc2b5a7f23aa820cef89e5a00a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
